# Generate training corpus 

### Datasets
  
Grobid NER has been trained on several different datasets :
 
 - Reuters NER [CONLL 2003](http://www.cnts.ua.ac.be/conll2003/ner/) manually annotated training data (10k words, 26 classes). This dataset is not public, so not shipped with the code. In order to obtain it, 
 
 - Manually annotated extract from the Wikipedia article on World War 1 (approximately 10k words, 26 classes)
  
The datasets distributed with this project are publicly available under the following licences: 
 
 - [Wikipedia](http://www.wikipedia.org) data is available under the licence [Creative Commons Attribution-ShareAlike License](https://creativecommons.org/licenses/by-sa/3.0/). 
 
 - [EHRI](https://portal.ehri-project.eu) data from the research portal, openly available as mentioned in the EHRI [data policy](https://portal.ehri-project.eu/data-policy).
 
  
The following datasets has been used as training data, but are not distributed with the project:
 
 - Reuters corpus, not publicly available. To obtain it, contact [NIST](http://trec.nist.gov/data/reuters/reuters.html).
